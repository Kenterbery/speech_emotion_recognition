{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from entropy import spectral_entropy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ravdess = \"/home/kenterbery/projects/speech_emotion_recognition/input/Ravdess/audio_speech_actors_01-24/\"\n",
    "Crema = \"/home/kenterbery/projects/speech_emotion_recognition/input/Crema/\"\n",
    "Savee = \"/home/kenterbery/projects/speech_emotion_recognition/input/Savee/\"\n",
    "Tess = \"/home/kenterbery/projects/speech_emotion_recognition/input/Tess/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ravdess dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(Ravdess + dir)\n",
    "    for wav in actor:\n",
    "        info = wav.partition(\".wav\")[0].split(\"-\")\n",
    "        emotion = int(info[2])\n",
    "        emotion_df.append((emotion, Ravdess + dir + \"/\" + wav))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ravdess_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Ravdess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ravdess_df.Emotion.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Crema dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emotion_df = []\n",
    "\n",
    "for wav in os.listdir(Crema):\n",
    "    info = wav.partition(\".wav\")[0].split(\"_\")\n",
    "    if info[2] == 'SAD':\n",
    "        emotion_df.append((\"sad\", Crema + wav))\n",
    "    elif info[2] == 'ANG':\n",
    "        emotion_df.append((\"angry\", Crema + wav))\n",
    "    elif info[2] == 'DIS':\n",
    "        emotion_df.append((\"disgust\", Crema + wav))\n",
    "    elif info[2] == 'FEA':\n",
    "        emotion_df.append((\"fear\", Crema + wav))\n",
    "    elif info[2] == 'HAP':\n",
    "        emotion_df.append((\"happy\", Crema + wav))\n",
    "    elif info[2] == 'NEU':\n",
    "        emotion_df.append((\"neutral\", Crema + wav))\n",
    "    else:\n",
    "        emotion_df.append((\"unknown\", Crema + wav))\n",
    "\n",
    "\n",
    "Crema_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Crema_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Crema_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TESS dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    for wav in os.listdir(Tess + dir):\n",
    "        info = wav.partition(\".wav\")[0].split(\"_\")\n",
    "        emo = info[2]\n",
    "        if emo == \"ps\":\n",
    "            emotion_df.append((\"surprise\", Tess + dir + \"/\" + wav))\n",
    "        else:\n",
    "            emotion_df.append((emo, Tess + dir + \"/\" + wav))\n",
    "\n",
    "\n",
    "Tess_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Tess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Tess_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "savee_directiory_list = os.listdir(Savee)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for wav in savee_directiory_list:\n",
    "    info = wav.partition(\".wav\")[0].split(\"_\")[1].replace(r\"[0-9]\", \"\")\n",
    "    emotion = re.split(r\"[0-9]\", info)[0]\n",
    "    if emotion=='a':\n",
    "        emotion_df.append((\"angry\", Savee + wav))\n",
    "    elif emotion=='d':\n",
    "        emotion_df.append((\"disgust\", Savee + wav))\n",
    "    elif emotion=='f':\n",
    "        emotion_df.append((\"fear\", Savee + wav))\n",
    "    elif emotion=='h':\n",
    "        emotion_df.append((\"happy\", Savee + wav))\n",
    "    elif emotion=='n':\n",
    "        emotion_df.append((\"neutral\", Savee + wav))\n",
    "    elif emotion=='sa':\n",
    "        emotion_df.append((\"sad\", Savee + wav))\n",
    "    else:\n",
    "        emotion_df.append((\"surprise\", Savee + wav))\n",
    "\n",
    "\n",
    "Savee_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Savee_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Savee_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis=0)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploratory data analysis\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title(\"Count of emotions:\")\n",
    "sns.countplot(x=df[\"Emotion\"])\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, emo):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.title(f\"Waveplot for .wav with {emo} emotion\")\n",
    "    librosa.display.waveplot(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr, emo):\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.title(f\"Spectrogram for .wav with {emo} emotion\")\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis=\"time\", y_axis=\"hz\")\n",
    "    # librosa.display.specshow(Xdb, sr=sr, x_axis=\"time\", y_axis=\"log\")\n",
    "    plt.colorbar()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emotions = [\"happy\", \"sad\",  \"angry\", \"fear\"]\n",
    "for emotion in emotions:\n",
    "    for i in range(10):\n",
    "        path = np.array(df[\"Path\"][df[\"Emotion\"] == emotion])[i]\n",
    "        data, sampling_rate = librosa.load(path)\n",
    "        # create_waveplot(data, sampling_rate, emotion)\n",
    "        create_spectrogram(data, sampling_rate, emotion)\n",
    "        # Audio(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def noise(data, rate=0.035):\n",
    "    noise_amp = rate*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data, rate=1000):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*rate)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = np.array(df.Path)[100]\n",
    "data, sampling_rate = librosa.load(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Simple audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(data, sampling_rate)\n",
    "Audio(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Noised audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noised_data = noise(data)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=noised_data, sr=sampling_rate)\n",
    "Audio(noised_data, rate=sampling_rate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Stretching\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stretched_data = stretch(data, rate=0.5)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=stretched_data, sr=sampling_rate)\n",
    "Audio(stretched_data, rate=sampling_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Shifting\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shifted_data = shift(data)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=shifted_data, sr=sampling_rate)\n",
    "Audio(shifted_data, rate=sampling_rate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Pitching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pitched_data = pitch(data, sampling_rate, pitch_factor=0.5)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=pitched_data, sr=sampling_rate)\n",
    "Audio(pitched_data, rate=sampling_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For data augmentation we will use noise, shift and pitch\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature extraction\n",
    "\n",
    "#### Features which may be useful:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Zero Crossing Rate : The rate of sign-changes of the signal during the duration of a particular frame.\n",
    "2. Energy : The sum of squares of the signal values, normalized by the respective frame length.\n",
    "3. Entropy of Energy :The entropy of sub-framesâ€™ normalized energies. It can be interpreted as a measure of abrupt changes.\n",
    "3. Spectral Centroid : The center of gravity of the spectrum.\n",
    "4. Spectral Spread : The second central moment of the spectrum.\n",
    "5. Spectral Entropy : Entropy of the normalized spectral energies for a set of sub-frames.\n",
    "6. Spectral Flux : The squared difference between the normalized magnitudes of the spectra of the two successive frames.\n",
    "7. Spectral Rolloff : The frequency below which 90% of the magnitude distribution of the spectrum is concentrated.\n",
    "8. MFCCs Mel Frequency Cepstral Coefficients form a cepstral representation where the frequency bands are not linear but distributed according to the mel-scale."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = 512"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def chunks(data, frame_length, hop_length):\n",
    "    \"\"\"\n",
    "    Split data to chunks with size frame_length and every hop_length.\n",
    "    :param data: np.array\n",
    "    :param frame_length: Int\n",
    "    :param hop_length: Int\n",
    "    :return: <generator>\n",
    "    \"\"\"\n",
    "    for i in range(0, len(data), hop_length):\n",
    "        yield data[i:i+frame_length]\n",
    "\n",
    "# Zero Crossing Rate\n",
    "def zcr(data, frame_length=2048, hop_length=512):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "\n",
    "def energy(data, frame_length=2048, hop_length=512):\n",
    "    en = np.array([np.sum(np.power(np.abs(data[hop:hop+frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n",
    "    return en / frame_length\n",
    "\n",
    "\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "\n",
    "def entropy_of_energy(data, frame_length=2048, hop_length=512):\n",
    "    energies = energy(data, frame_length, hop_length)\n",
    "    energies /= np.sum(energies)\n",
    "\n",
    "    entropy = 0.0\n",
    "    entropy -= energies * np.log2(energies)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def spc(data, sr, frame_length=2048, hop_length=512):\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(spectral_centroid)\n",
    "\n",
    "\n",
    "def spc_entropy(data, sr):\n",
    "    spc_en = spectral_entropy(data, sf=sr, method=\"fft\")\n",
    "    return spc_en\n",
    "\n",
    "def spc_flux(data):\n",
    "    isSpectrum = data.ndim == 1\n",
    "    if isSpectrum:\n",
    "        data = np.expand_dims(data, axis=1)\n",
    "\n",
    "    X = np.c_[data[:, 0], data]\n",
    "    af_Delta_X = np.diff(X, 1, axis=1)\n",
    "    vsf = np.sqrt((np.power(af_Delta_X, 2).sum(axis=0))) / X.shape[0]\n",
    "\n",
    "    return np.squeeze(vsf) if isSpectrum else vsf\n",
    "\n",
    "\n",
    "def spc_rollof(data, sr, frame_length=2048, hop_length=512):\n",
    "    spcrollof = librosa.feature.spectral_rolloff(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(spcrollof)\n",
    "\n",
    "\n",
    "def chroma_stft(data, sr, frame_length=2048, hop_length=512):\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
    "    return np.squeeze(chroma_stft.T)\n",
    "\n",
    "\n",
    "def mel_spc(data, sr, frame_length=2048, hop_length=512):\n",
    "    mel = librosa.feature.melspectrogram(y=data, sr=sr)\n",
    "    return np.squeeze(mel.T)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Let's check data formats:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = np.array(df[\"Path\"])[1]\n",
    "data, sample_rate = librosa.load(path)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"ZCR: \", zcr(data).shape)\n",
    "print(\"Energy: \", energy(data).shape)\n",
    "print(\"Entropy of Energy :\", entropy_of_energy(data).shape)\n",
    "print(\"RMS :\", rmse(data).shape)\n",
    "print(\"Spectral Centroid :\", spc(data, sampling_rate).shape)\n",
    "print(\"Spectral Entropy: \", spc_entropy(data, sampling_rate).shape)\n",
    "print(\"Spectral Flux: \", spc_flux(data).shape)\n",
    "print(\"Spectral Rollof: \", spc_rollof(data, sampling_rate).shape)\n",
    "print(\"Chroma STFT: \", chroma_stft(data, sampling_rate).shape)\n",
    "print(\"MelSpectrogram: \", mel_spc(data, sampling_rate).shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}